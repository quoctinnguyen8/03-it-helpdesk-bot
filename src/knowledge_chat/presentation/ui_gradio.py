"""Gradio-based user interface for the IT Helpdesk Bot with RAG.

This UI allows users to:
1. Upload multiple text documents to build a knowledge base.
2. Chat directly with the AI assistant with streaming responses,
   which retrieves context from the vector store and provides
   referenced, context-aware answers in multiple languages.

Enhanced features:
- Streaming responses (typewriter effect)
- Progress bar for document import
- Multi-language support (English/Vietnamese)
"""

import time
from typing import Generator, List

import gradio as gr

from knowledge_chat.application.chat_use_case import ChatUseCase
from knowledge_chat.application.import_files_use_case import ImportFilesUseCase
from knowledge_chat.domain.entities.message import Message, MessageType


class KnowledgeChatUI:
    """Gradio-based UI for IT Helpdesk Bot with document ingestion and AI chat."""

    def __init__(
        self,
        import_use_case: ImportFilesUseCase,
        chat_use_case: ChatUseCase,
    ) -> None:
        """Initialize the UI with application use cases."""
        self._import_use_case = import_use_case
        self._chat_use_case = chat_use_case
        self._messages: List[Message] = []
        self._uploaded_files: List[str] = []

    # -----------------------------------------------------
    # UI Construction
    # -----------------------------------------------------

    def create_interface(self) -> gr.Blocks:
        """Create and return the Gradio UI layout with enhanced features."""
        theme = gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="sky",
            neutral_hue="gray",
            font=[gr.themes.GoogleFont("Roboto")],
        )

        with gr.Blocks(
            theme=theme,
            title="IT Helpdesk Bot (RAG)",
            css="""
                #title {
                    text-align: center;
                    font-size: 2em;
                    color: #2563eb;
                    margin-bottom: 10px;
                }
                #subtitle {
                    text-align: center;
                    font-size: 1.1em;
                    color: #555;
                    margin-bottom: 30px;
                }
                .gr-button {
                    border-radius: 10px !important;
                    font-weight: 600;
                }
                .gradio-container {
                    background-color: #fafafa !important;
                }
                .chatbox {
                    min-height: 500px;
                    max-height: 600px;
                    overflow-y: auto;
                }
            """,
        ) as demo:
            gr.Markdown("<h1 id='title'>IT Helpdesk Bot</h1>")
            gr.Markdown(
                "<p id='subtitle'>Upload IT troubleshooting documents and chat with AI ‚Äî powered by RAG | "
                "H·ªó tr·ª£ ti·∫øng Vi·ªát & English</p>"
            )

            with gr.Tabs():
                # =============================================================
                # TAB 1: DOCUMENT UPLOAD WITH PROGRESS BAR
                # =============================================================
                with gr.TabItem("üìÅ Import Documents"):
                    gr.Markdown("### Step 1: Upload documents to build the knowledge base.")
                    gr.Markdown("_Supported formats: TXT, PDF, Markdown (.md), JSON | ƒê·ªãnh d·∫°ng h·ªó tr·ª£: TXT, PDF, Markdown (.md), JSON_")
                    gr.Markdown("_Supported languages: English, Vietnamese | H·ªó tr·ª£: Ti·∫øng Anh, Ti·∫øng Vi·ªát_")
                    
                    file_input = gr.File(
                        file_types=[".txt", ".pdf", ".md", ".markdown", ".json"],
                        file_count="multiple",
                        label="Upload files (TXT, PDF, MD, JSON) | T·∫£i l√™n file (TXT, PDF, MD, JSON)",
                    )
                    import_status = gr.Markdown("‚ÑπÔ∏è _Waiting for files... | ƒêang ch·ªù file..._")
                    import_progress = gr.Progress()
                    file_table = gr.DataFrame(
                        headers=["File Name"],
                        label="Imported Documents | T√†i li·ªáu ƒë√£ nh·∫≠p",
                        interactive=False,
                    )

                    def import_files(files, progress=gr.Progress()):
                        """Handle file upload and document import with progress bar."""
                        if not files:
                            return "‚ö†Ô∏è Please upload at least one file. | Vui l√≤ng t·∫£i l√™n √≠t nh·∫•t m·ªôt file.", None
                        
                        try:
                            paths = [f.name for f in files]
                            self._uploaded_files = [f.name.split("/")[-1].split("\\")[-1] for f in files]
                            
                            # Show progress for import process
                            progress(0, desc="Starting import... | B·∫Øt ƒë·∫ßu nh·∫≠p...")
                            time.sleep(0.5)
                            
                            progress(0.2, desc="Loading documents... | ƒêang t·∫£i t√†i li·ªáu...")
                            time.sleep(0.3)
                            
                            progress(0.4, desc="Chunking text... | ƒêang chia nh·ªè vƒÉn b·∫£n...")
                            time.sleep(0.3)
                            
                            progress(0.6, desc="Generating embeddings... | ƒêang t·∫°o embeddings...")
                            self._import_use_case.invoke(paths)
                            
                            progress(0.9, desc="Storing in database... | ƒêang l∆∞u v√†o database...")
                            time.sleep(0.3)
                            
                            progress(1.0, desc="Import completed! | Ho√†n th√†nh!")
                            
                            table_data = [[name] for name in self._uploaded_files]
                            return (
                                f"‚úÖ Successfully imported {len(paths)} file(s) into the vector store. | "
                                f"ƒê√£ nh·∫≠p th√†nh c√¥ng {len(paths)} file v√†o c∆° s·ªü ki·∫øn th·ª©c.",
                                table_data,
                            )
                        # pylint: disable=broad-exception-caught
                        except Exception as e:
                            return f"‚ùå Error while importing files: {str(e)} | L·ªói khi nh·∫≠p file: {str(e)}", None

                    file_input.change(  # pylint: disable=no-member
                        fn=import_files,
                        inputs=file_input,
                        outputs=[import_status, file_table],
                    )

                # =============================================================
                # TAB 2: CHAT INTERFACE WITH STREAMING
                # =============================================================
                with gr.TabItem("üí¨ Chat with AI"):
                    gr.Markdown("### Step 2: Start chatting with your IT Helpdesk AI assistant!")
                    gr.Markdown("_Ask questions in English or Vietnamese | H·ªèi b·∫±ng ti·∫øng Anh ho·∫∑c ti·∫øng Vi·ªát_")

                    chat_box = gr.Chatbot(
                        label="Chat Window | C·ª≠a s·ªï chat",
                        elem_classes=["chatbox"],
                        height=400,
                    )

                    user_input = gr.Textbox(
                        placeholder="Type your message and press Enter... | Nh·∫≠p tin nh·∫Øn v√† nh·∫•n Enter...",
                        label="Your Message | Tin nh·∫Øn c·ªßa b·∫°n",
                        lines=2,
                    )

                    send_button = gr.Button("üöÄ Send | G·ª≠i", variant="primary")
                    clear_button = gr.Button("üßπ Clear Chat | X√≥a chat", variant="secondary")

                    # ------------------ Chat Logic with Streaming ------------------
                    def chat_stream(user_message: str, history: List[List[str]]) -> Generator:
                        """Handle user input and generate AI response with streaming effect."""
                        if not user_message.strip():
                            yield history
                            return

                        self._messages.append(
                            Message(type=MessageType.USER, content=user_message)
                        )

                        try:
                            # Get AI response
                            ai_message = self._chat_use_case.invoke(self._messages)
                            self._messages.append(ai_message)
                            
                            # Add user message to history
                            history.append(["üßë‚Äçüí¨ " + user_message, ""])
                            
                            # Stream AI response character by character (typewriter effect)
                            response_text = "ü§ñ " + ai_message.content
                            displayed_text = ""
                            
                            for char in response_text:
                                displayed_text += char
                                history[-1][1] = displayed_text
                                time.sleep(0.01)  # Adjust speed here
                                yield history
                                
                        # pylint: disable=broad-exception-caught
                        except Exception as e:
                            history.append(
                                ["üßë‚Äçüí¨ " + user_message, f"‚ùå Error | L·ªói: {str(e)}"]
                            )
                            yield history

                    def clear_chat():
                        """Reset the entire chat session."""
                        self._messages.clear()
                        return []

                    # Bind events
                    send_button.click(  # pylint: disable=no-member
                        fn=chat_stream,
                        inputs=[user_input, chat_box],
                        outputs=chat_box,
                    ).then(
                        fn=lambda: "",  # Clear input after sending
                        inputs=None,
                        outputs=user_input,
                    )

                    user_input.submit(  # pylint: disable=no-member
                        fn=chat_stream,
                        inputs=[user_input, chat_box],
                        outputs=chat_box,
                    ).then(
                        fn=lambda: "",  # Clear input after sending
                        inputs=None,
                        outputs=user_input,
                    )

                    clear_button.click(  # pylint: disable=no-member
                        fn=clear_chat,
                        inputs=None,
                        outputs=chat_box,
                    )

        return demo
